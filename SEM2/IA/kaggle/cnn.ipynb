{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "# import torchvision.transforms as transforms\n",
    "\n",
    "from PIL import Image\n",
    "from torch.optim import SGD\n",
    "from tqdm import tqdm\n",
    "\n",
    "from dataset_class import get_dataloader\n",
    "# from cnn_class import CnnModel\n",
    "# from torch.utils.data import DataLoader\n",
    "# from test_model import CnnModel\n",
    "from torch.nn.functional import softmax\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"./data/train1.txt\", sep=',')\n",
    "\n",
    "validation_data = pd.read_csv(\"./data/validation1.txt\", sep=',')\n",
    "\n",
    "test_data = pd.read_csv(\"./data/test.txt\", sep=',')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "1173"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(validation_data.id)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def return_pixel_rgb_values(img_name, path = \"./data/train_validation/\") :\n",
    "    return np.array(list(Image.open(path + img_name).getdata())).reshape((16, 16, 3))\n",
    "\n",
    "\n",
    "train_images = np.array([return_pixel_rgb_values(x) for x in train_data.id])/255\n",
    "\n",
    "validation_images = np.array([return_pixel_rgb_values(x) for x in validation_data.id])/255\n",
    "\n",
    "test_images = np.array([return_pixel_rgb_values(x, \"./data/test/\") for x in test_data.id])/255\n",
    "\n",
    "\n",
    "\n",
    "train_mean_image = np.mean(train_images, axis=(0,1,2))\n",
    "\n",
    "validation_mean_image = np.mean(validation_images, axis=(0,1,2))\n",
    "\n",
    "test_mean_image = np.mean(test_images, axis=(0,1,2))\n",
    "\n",
    "\n",
    "train_std = np.std(train_images, axis=(0,1,2))\n",
    "\n",
    "validation_std = np.std(validation_images, axis=(0,1,2))\n",
    "\n",
    "test_std = np.std(test_images, axis=(0,1,2))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "\n",
    "train_dataloader = get_dataloader(\"./data/train_validation/\", \"./data/train_txt.txt\", \"train\", tuple(train_mean_image), tuple(train_mean_image), batch_size=7)\n",
    "validation_dataloader = get_dataloader(\"./data/train_validation/\", \"./data/validation_txt.txt\", \"validation\", tuple(validation_mean_image), tuple(validation_std), batch_size=7)\n",
    "# test_dataloader = get_dataloader(\"./data/test/\", \"./data/sample_submission.txt\", \"test\", test_mean_image, test_std)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def train_model(model, optimizer, criterion, train_dataloader, epoch, writer) :\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for images,labels in tqdm(train_dataloader, \"Train\"):\n",
    "\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * len(images)\n",
    "\n",
    "    running_loss /= len(train_dataloader.dataset)\n",
    "\n",
    "    writer.add_scalar(tag=\"Loss/Train\", scalar_value=running_loss, global_step=epoch)\n",
    "    writer.flush()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "def eval_model(model, validation_dataloader, criterion, epoch, writer, best_loss, second_loss, best_accuracy, second_accuracy, nr, validation = True):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    true_preds = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images,labels in tqdm(validation_dataloader, \"Validation\"):\n",
    "\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            logits = model(images)\n",
    "\n",
    "            # Compute the loss\n",
    "            loss = criterion(logits, labels)\n",
    "\n",
    "            # Compute accuracy\n",
    "            scores = softmax(logits, dim=1)\n",
    "\n",
    "            # Get the prediction labels\n",
    "            pred_label = torch.argmax(scores, dim=1)\n",
    "\n",
    "            # Get the acc\n",
    "            true_preds += (pred_label == labels).sum()\n",
    "\n",
    "            running_loss += loss.item() * len(images)\n",
    "\n",
    "        accuracy = true_preds / len(validation_dataloader.dataset)\n",
    "        print(f\"acc is {accuracy}\")\n",
    "        if accuracy > 0.62:\n",
    "            save_model(model,\"./models/\", \"greater_62\")\n",
    "        if accuracy > 0.605:\n",
    "            save_model(model,\"./models/\", \"greater_60\")\n",
    "        running_loss = running_loss / len(validation_dataloader.dataset)\n",
    "\n",
    "        if validation :\n",
    "            writer.add_scalar(scalar_value=accuracy, tag=\"Acc/Valid\", global_step=epoch)\n",
    "            writer.add_scalar(scalar_value=running_loss, tag=\"Loss/Valid\", global_step=epoch)\n",
    "        else :\n",
    "             writer.add_scalar(scalar_value=accuracy, tag=\"Acc/Train\", global_step=epoch)\n",
    "\n",
    "        writer.flush()\n",
    "\n",
    "        if running_loss < best_loss :\n",
    "             torch.save(model.state_dict(), \"./models/best_loss.pth\")\n",
    "             best_loss = running_loss\n",
    "             print(\" am salvat modelul cu best loss\")\n",
    "        elif running_loss < second_loss :\n",
    "             torch.save(model.state_dict(), \"./models/second_loss.pth\")\n",
    "             second_loss = running_loss\n",
    "             print(\" am salvat modelul cu second loss\")\n",
    "\n",
    "        if accuracy > best_accuracy :\n",
    "             torch.save(model.state_dict(), \"./models/best_acc.pth\")\n",
    "             best_accuracy = accuracy\n",
    "             print(\" am salvat modelul cu best acc\")\n",
    "        elif accuracy > second_accuracy :\n",
    "             torch.save(model.state_dict(), \"./models/second_acc.pth\")\n",
    "             second_accuracy = accuracy\n",
    "             print(\" am salvat modelul cu second acc\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "def save_model(model, path, model_no):\n",
    "    torch.save(model.state_dict(), path + f\"model{model_no}.pth\")\n",
    "    print(\"am salvat modelul\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    " def run_model(lr, epochs, name_log, nr):\n",
    "    best_loss = 99999.0\n",
    "    second_loss = 99999.0\n",
    "    best_accuracy = 0.0\n",
    "    second_accuracy = 0.0\n",
    "\n",
    "    model = CnnModel()\n",
    "\n",
    "    model = model.to(device)\n",
    "\n",
    "    optimizer = SGD(model.parameters(), lr = lr)\n",
    "\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    writer = SummaryWriter(log_dir=\"./logs/model_\" + name_log)\n",
    "\n",
    "    for epoch in range(epochs) :\n",
    "        train_model(model, optimizer, criterion, train_dataloader, epoch, writer)\n",
    "        # train_model(model, optimizer, criterion, validation_dataloader, epoch, writer)\n",
    "        eval_model(model, validation_dataloader, criterion, epoch, writer, best_loss, second_loss, best_accuracy, second_accuracy, nr, validation=True)\n",
    "        # eval_model(model, validation_dataloader, criterion, epoch, writer, best_loss, second_loss, best_accuracy, second_accuracy, nr, validation=False)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "dataloader_test = get_dataloader(\"./data/test/\", \"./data/sample_submission.txt\",\"dani\", test_mean_image, test_std)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 1143/1143 [00:07<00:00, 153.51it/s]\n",
      "Validation: 100%|██████████| 168/168 [00:00<00:00, 286.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc is 0.44075021147727966\n",
      " am salvat modelul cu best loss\n",
      " am salvat modelul cu best acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 1143/1143 [00:07<00:00, 157.32it/s]\n",
      "Validation: 100%|██████████| 168/168 [00:00<00:00, 287.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc is 0.47229325771331787\n",
      " am salvat modelul cu best loss\n",
      " am salvat modelul cu best acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 1143/1143 [00:07<00:00, 158.85it/s]\n",
      "Validation: 100%|██████████| 168/168 [00:00<00:00, 286.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc is 0.5072463750839233\n",
      " am salvat modelul cu best loss\n",
      " am salvat modelul cu best acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 1143/1143 [00:07<00:00, 159.30it/s]\n",
      "Validation: 100%|██████████| 168/168 [00:00<00:00, 286.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc is 0.5191816091537476\n",
      " am salvat modelul cu best loss\n",
      " am salvat modelul cu best acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 1143/1143 [00:07<00:00, 160.27it/s]\n",
      "Validation: 100%|██████████| 168/168 [00:00<00:00, 278.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc is 0.5609548091888428\n",
      " am salvat modelul cu best loss\n",
      " am salvat modelul cu best acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 1143/1143 [00:07<00:00, 154.06it/s]\n",
      "Validation: 100%|██████████| 168/168 [00:00<00:00, 283.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc is 0.5524296760559082\n",
      " am salvat modelul cu best loss\n",
      " am salvat modelul cu best acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 1143/1143 [00:07<00:00, 157.74it/s]\n",
      "Validation: 100%|██████████| 168/168 [00:00<00:00, 284.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc is 0.5575447678565979\n",
      " am salvat modelul cu best loss\n",
      " am salvat modelul cu best acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 1143/1143 [00:07<00:00, 159.56it/s]\n",
      "Validation: 100%|██████████| 168/168 [00:00<00:00, 282.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc is 0.5907928347587585\n",
      " am salvat modelul cu best loss\n",
      " am salvat modelul cu best acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 1143/1143 [00:07<00:00, 156.99it/s]\n",
      "Validation: 100%|██████████| 168/168 [00:00<00:00, 287.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc is 0.5907928347587585\n",
      " am salvat modelul cu best loss\n",
      " am salvat modelul cu best acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 1143/1143 [00:07<00:00, 154.24it/s]\n",
      "Validation: 100%|██████████| 168/168 [00:00<00:00, 278.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc is 0.5848252177238464\n",
      " am salvat modelul cu best loss\n",
      " am salvat modelul cu best acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 1143/1143 [00:07<00:00, 158.13it/s]\n",
      "Validation: 100%|██████████| 168/168 [00:00<00:00, 288.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc is 0.6035805940628052\n",
      " am salvat modelul cu best loss\n",
      " am salvat modelul cu best acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 1143/1143 [00:07<00:00, 158.59it/s]\n",
      "Validation: 100%|██████████| 168/168 [00:00<00:00, 286.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc is 0.6044330596923828\n",
      " am salvat modelul cu best loss\n",
      " am salvat modelul cu best acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 1143/1143 [00:07<00:00, 155.36it/s]\n",
      "Validation: 100%|██████████| 168/168 [00:00<00:00, 285.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc is 0.6121057271957397\n",
      "am salvat modelul\n",
      " am salvat modelul cu best loss\n",
      " am salvat modelul cu best acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 1143/1143 [00:07<00:00, 157.31it/s]\n",
      "Validation: 100%|██████████| 168/168 [00:00<00:00, 274.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc is 0.5942029356956482\n",
      " am salvat modelul cu best loss\n",
      " am salvat modelul cu best acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 1143/1143 [00:07<00:00, 158.95it/s]\n",
      "Validation: 100%|██████████| 168/168 [00:00<00:00, 285.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc is 0.6010230183601379\n",
      " am salvat modelul cu best loss\n",
      " am salvat modelul cu best acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 1143/1143 [00:07<00:00, 155.96it/s]\n",
      "Validation: 100%|██████████| 168/168 [00:00<00:00, 283.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc is 0.6052855849266052\n",
      "am salvat modelul\n",
      " am salvat modelul cu best loss\n",
      " am salvat modelul cu best acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 1143/1143 [00:07<00:00, 158.87it/s]\n",
      "Validation: 100%|██████████| 168/168 [00:00<00:00, 282.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc is 0.6104006767272949\n",
      "am salvat modelul\n",
      " am salvat modelul cu best loss\n",
      " am salvat modelul cu best acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 1143/1143 [00:07<00:00, 159.23it/s]\n",
      "Validation: 100%|██████████| 168/168 [00:00<00:00, 280.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc is 0.6172208189964294\n",
      "am salvat modelul\n",
      " am salvat modelul cu best loss\n",
      " am salvat modelul cu best acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 1143/1143 [00:07<00:00, 159.61it/s]\n",
      "Validation: 100%|██████████| 168/168 [00:00<00:00, 289.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc is 0.6086956858634949\n",
      "am salvat modelul\n",
      " am salvat modelul cu best loss\n",
      " am salvat modelul cu best acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 1143/1143 [00:07<00:00, 158.58it/s]\n",
      "Validation: 100%|██████████| 168/168 [00:00<00:00, 287.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc is 0.6223359107971191\n",
      "am salvat modelul\n",
      "am salvat modelul\n",
      " am salvat modelul cu best loss\n",
      " am salvat modelul cu best acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 1143/1143 [00:07<00:00, 158.97it/s]\n",
      "Validation: 100%|██████████| 168/168 [00:00<00:00, 287.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc is 0.6214833855628967\n",
      "am salvat modelul\n",
      "am salvat modelul\n",
      " am salvat modelul cu best loss\n",
      " am salvat modelul cu best acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 1143/1143 [00:07<00:00, 156.63it/s]\n",
      "Validation: 100%|██████████| 168/168 [00:00<00:00, 284.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc is 0.6044330596923828\n",
      " am salvat modelul cu best loss\n",
      " am salvat modelul cu best acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 1143/1143 [00:07<00:00, 156.79it/s]\n",
      "Validation: 100%|██████████| 168/168 [00:00<00:00, 284.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc is 0.6010230183601379\n",
      " am salvat modelul cu best loss\n",
      " am salvat modelul cu best acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 1143/1143 [00:07<00:00, 159.60it/s]\n",
      "Validation: 100%|██████████| 168/168 [00:00<00:00, 287.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc is 0.5873827934265137\n",
      " am salvat modelul cu best loss\n",
      " am salvat modelul cu best acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 1143/1143 [00:07<00:00, 156.42it/s]\n",
      "Validation: 100%|██████████| 168/168 [00:00<00:00, 286.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc is 0.6265984773635864\n",
      "am salvat modelul\n",
      "am salvat modelul\n",
      " am salvat modelul cu best loss\n",
      " am salvat modelul cu best acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 1143/1143 [00:07<00:00, 155.96it/s]\n",
      "Validation: 100%|██████████| 168/168 [00:00<00:00, 275.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc is 0.5882353186607361\n",
      " am salvat modelul cu best loss\n",
      " am salvat modelul cu best acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 1143/1143 [00:07<00:00, 152.77it/s]\n",
      "Validation: 100%|██████████| 168/168 [00:00<00:00, 271.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc is 0.5976129770278931\n",
      " am salvat modelul cu best loss\n",
      " am salvat modelul cu best acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 1143/1143 [00:07<00:00, 149.55it/s]\n",
      "Validation: 100%|██████████| 168/168 [00:00<00:00, 267.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc is 0.6138107776641846\n",
      "am salvat modelul\n",
      " am salvat modelul cu best loss\n",
      " am salvat modelul cu best acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 1143/1143 [00:07<00:00, 152.92it/s]\n",
      "Validation: 100%|██████████| 168/168 [00:00<00:00, 273.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc is 0.5720375180244446\n",
      " am salvat modelul cu best loss\n",
      " am salvat modelul cu best acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 1143/1143 [00:07<00:00, 153.74it/s]\n",
      "Validation: 100%|██████████| 168/168 [00:00<00:00, 279.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc is 0.6095481514930725\n",
      "am salvat modelul\n",
      " am salvat modelul cu best loss\n",
      " am salvat modelul cu best acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 1143/1143 [00:07<00:00, 157.75it/s]\n",
      "Validation: 100%|██████████| 168/168 [00:00<00:00, 281.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc is 0.6035805940628052\n",
      " am salvat modelul cu best loss\n",
      " am salvat modelul cu best acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 1143/1143 [00:07<00:00, 159.99it/s]\n",
      "Validation: 100%|██████████| 168/168 [00:00<00:00, 276.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc is 0.6121057271957397\n",
      "am salvat modelul\n",
      " am salvat modelul cu best loss\n",
      " am salvat modelul cu best acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 1143/1143 [00:07<00:00, 159.72it/s]\n",
      "Validation: 100%|██████████| 168/168 [00:00<00:00, 279.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc is 0.5933504104614258\n",
      " am salvat modelul cu best loss\n",
      " am salvat modelul cu best acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 1143/1143 [00:07<00:00, 157.53it/s]\n",
      "Validation: 100%|██████████| 168/168 [00:00<00:00, 288.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc is 0.5805626511573792\n",
      " am salvat modelul cu best loss\n",
      " am salvat modelul cu best acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 1143/1143 [00:07<00:00, 159.24it/s]\n",
      "Validation: 100%|██████████| 168/168 [00:00<00:00, 280.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc is 0.6061381101608276\n",
      "am salvat modelul\n",
      " am salvat modelul cu best loss\n",
      " am salvat modelul cu best acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 1143/1143 [00:07<00:00, 161.44it/s]\n",
      "Validation: 100%|██████████| 168/168 [00:00<00:00, 288.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc is 0.6052855849266052\n",
      "am salvat modelul\n",
      " am salvat modelul cu best loss\n",
      " am salvat modelul cu best acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 1143/1143 [00:07<00:00, 160.31it/s]\n",
      "Validation: 100%|██████████| 168/168 [00:00<00:00, 280.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc is 0.6138107776641846\n",
      "am salvat modelul\n",
      " am salvat modelul cu best loss\n",
      " am salvat modelul cu best acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 1143/1143 [00:07<00:00, 159.63it/s]\n",
      "Validation: 100%|██████████| 168/168 [00:00<00:00, 288.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc is 0.5899403095245361\n",
      " am salvat modelul cu best loss\n",
      " am salvat modelul cu best acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:  21%|██        | 237/1143 [00:01<00:05, 153.40it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[1;32mIn [16]\u001B[0m, in \u001B[0;36m<cell line: 3>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m lr \u001B[38;5;129;01min\u001B[39;00m [\u001B[38;5;241m0.01\u001B[39m, \u001B[38;5;241m0.1\u001B[39m] :\n\u001B[0;32m      4\u001B[0m     epoch \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m400\u001B[39m\n\u001B[1;32m----> 5\u001B[0m     \u001B[43mrun_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlr\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepoch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mtest_nr\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;28;43mstr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mk\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mk\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      6\u001B[0m     k \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n",
      "Input \u001B[1;32mIn [11]\u001B[0m, in \u001B[0;36mrun_model\u001B[1;34m(lr, epochs, name_log, nr)\u001B[0m\n\u001B[0;32m     15\u001B[0m writer \u001B[38;5;241m=\u001B[39m SummaryWriter(log_dir\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m./logs/model_\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m+\u001B[39m name_log)\n\u001B[0;32m     17\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m epoch \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(epochs) :\n\u001B[1;32m---> 18\u001B[0m     \u001B[43mtrain_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcriterion\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_dataloader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepoch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mwriter\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     19\u001B[0m     \u001B[38;5;66;03m# train_model(model, optimizer, criterion, validation_dataloader, epoch, writer)\u001B[39;00m\n\u001B[0;32m     20\u001B[0m     eval_model(model, validation_dataloader, criterion, epoch, writer, best_loss, second_loss, best_accuracy, second_accuracy, nr, validation\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "Input \u001B[1;32mIn [8]\u001B[0m, in \u001B[0;36mtrain_model\u001B[1;34m(model, optimizer, criterion, train_dataloader, epoch, writer)\u001B[0m\n\u001B[0;32m      3\u001B[0m model\u001B[38;5;241m.\u001B[39mtrain()\n\u001B[0;32m      5\u001B[0m running_loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0.0\u001B[39m\n\u001B[1;32m----> 7\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m images,labels \u001B[38;5;129;01min\u001B[39;00m tqdm(train_dataloader, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTrain\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[0;32m      9\u001B[0m     images \u001B[38;5;241m=\u001B[39m images\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[0;32m     10\u001B[0m     labels \u001B[38;5;241m=\u001B[39m labels\u001B[38;5;241m.\u001B[39mto(device)\n",
      "File \u001B[1;32mc:\\documente\\facultate_an_2\\sem2\\ia\\kaggle\\venv\\lib\\site-packages\\tqdm\\std.py:1195\u001B[0m, in \u001B[0;36mtqdm.__iter__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1192\u001B[0m time \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_time\n\u001B[0;32m   1194\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 1195\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m obj \u001B[38;5;129;01min\u001B[39;00m iterable:\n\u001B[0;32m   1196\u001B[0m         \u001B[38;5;28;01myield\u001B[39;00m obj\n\u001B[0;32m   1197\u001B[0m         \u001B[38;5;66;03m# Update and possibly print the progressbar.\u001B[39;00m\n\u001B[0;32m   1198\u001B[0m         \u001B[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001B[39;00m\n",
      "File \u001B[1;32mc:\\documente\\facultate_an_2\\sem2\\ia\\kaggle\\venv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:530\u001B[0m, in \u001B[0;36m_BaseDataLoaderIter.__next__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    528\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sampler_iter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    529\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reset()\n\u001B[1;32m--> 530\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_next_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    531\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m    532\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_kind \u001B[38;5;241m==\u001B[39m _DatasetKind\u001B[38;5;241m.\u001B[39mIterable \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[0;32m    533\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[0;32m    534\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called:\n",
      "File \u001B[1;32mc:\\documente\\facultate_an_2\\sem2\\ia\\kaggle\\venv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:570\u001B[0m, in \u001B[0;36m_SingleProcessDataLoaderIter._next_data\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    568\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_next_data\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    569\u001B[0m     index \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_next_index()  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[1;32m--> 570\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_dataset_fetcher\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfetch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mindex\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[0;32m    571\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory:\n\u001B[0;32m    572\u001B[0m         data \u001B[38;5;241m=\u001B[39m _utils\u001B[38;5;241m.\u001B[39mpin_memory\u001B[38;5;241m.\u001B[39mpin_memory(data)\n",
      "File \u001B[1;32mc:\\documente\\facultate_an_2\\sem2\\ia\\kaggle\\venv\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:49\u001B[0m, in \u001B[0;36m_MapDatasetFetcher.fetch\u001B[1;34m(self, possibly_batched_index)\u001B[0m\n\u001B[0;32m     47\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfetch\u001B[39m(\u001B[38;5;28mself\u001B[39m, possibly_batched_index):\n\u001B[0;32m     48\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mauto_collation:\n\u001B[1;32m---> 49\u001B[0m         data \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[idx] \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m possibly_batched_index]\n\u001B[0;32m     50\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     51\u001B[0m         data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[possibly_batched_index]\n",
      "File \u001B[1;32mc:\\documente\\facultate_an_2\\sem2\\ia\\kaggle\\venv\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:49\u001B[0m, in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m     47\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfetch\u001B[39m(\u001B[38;5;28mself\u001B[39m, possibly_batched_index):\n\u001B[0;32m     48\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mauto_collation:\n\u001B[1;32m---> 49\u001B[0m         data \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdataset\u001B[49m\u001B[43m[\u001B[49m\u001B[43midx\u001B[49m\u001B[43m]\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m possibly_batched_index]\n\u001B[0;32m     50\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     51\u001B[0m         data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[possibly_batched_index]\n",
      "File \u001B[1;32mC:\\DOCUMENTE\\Facultate_AN_2\\Sem2\\IA\\kaggle\\dataset_class.py:48\u001B[0m, in \u001B[0;36mToyDataset.__getitem__\u001B[1;34m(self, idx)\u001B[0m\n\u001B[0;32m     45\u001B[0m label \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlabels[idx]\n\u001B[0;32m     47\u001B[0m \u001B[38;5;66;03m# Apply base transforms (all the modes)\u001B[39;00m\n\u001B[1;32m---> 48\u001B[0m img_transformed \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbase_transforms\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimg\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     50\u001B[0m \u001B[38;5;66;03m# Appy augs\u001B[39;00m\n\u001B[0;32m     51\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmode \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torchvision\\transforms\\transforms.py:95\u001B[0m, in \u001B[0;36mCompose.__call__\u001B[1;34m(self, img)\u001B[0m\n\u001B[0;32m     93\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, img):\n\u001B[0;32m     94\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m t \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtransforms:\n\u001B[1;32m---> 95\u001B[0m         img \u001B[38;5;241m=\u001B[39m \u001B[43mt\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimg\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     96\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m img\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torchvision\\transforms\\transforms.py:135\u001B[0m, in \u001B[0;36mToTensor.__call__\u001B[1;34m(self, pic)\u001B[0m\n\u001B[0;32m    127\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, pic):\n\u001B[0;32m    128\u001B[0m     \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    129\u001B[0m \u001B[38;5;124;03m    Args:\u001B[39;00m\n\u001B[0;32m    130\u001B[0m \u001B[38;5;124;03m        pic (PIL Image or numpy.ndarray): Image to be converted to tensor.\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    133\u001B[0m \u001B[38;5;124;03m        Tensor: Converted image.\u001B[39;00m\n\u001B[0;32m    134\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 135\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto_tensor\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpic\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torchvision\\transforms\\functional.py:147\u001B[0m, in \u001B[0;36mto_tensor\u001B[1;34m(pic)\u001B[0m\n\u001B[0;32m    145\u001B[0m \u001B[38;5;66;03m# handle PIL Image\u001B[39;00m\n\u001B[0;32m    146\u001B[0m mode_to_nptype \u001B[38;5;241m=\u001B[39m {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mI\u001B[39m\u001B[38;5;124m\"\u001B[39m: np\u001B[38;5;241m.\u001B[39mint32, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mI;16\u001B[39m\u001B[38;5;124m\"\u001B[39m: np\u001B[38;5;241m.\u001B[39mint16, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mF\u001B[39m\u001B[38;5;124m\"\u001B[39m: np\u001B[38;5;241m.\u001B[39mfloat32}\n\u001B[1;32m--> 147\u001B[0m img \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mfrom_numpy(\u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43marray\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpic\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmode_to_nptype\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpic\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43muint8\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcopy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m)\n\u001B[0;32m    149\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m pic\u001B[38;5;241m.\u001B[39mmode \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m1\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m    150\u001B[0m     img \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m255\u001B[39m \u001B[38;5;241m*\u001B[39m img\n",
      "File \u001B[1;32mc:\\documente\\facultate_an_2\\sem2\\ia\\kaggle\\venv\\lib\\site-packages\\PIL\\Image.py:675\u001B[0m, in \u001B[0;36mImage.__array__\u001B[1;34m(self, dtype)\u001B[0m\n\u001B[0;32m    673\u001B[0m     new[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdata\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtobytes(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mraw\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mL\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    674\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 675\u001B[0m     new[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdata\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtobytes\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    677\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m np\u001B[38;5;241m.\u001B[39marray(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_ArrayData(new), dtype)\n",
      "File \u001B[1;32mc:\\documente\\facultate_an_2\\sem2\\ia\\kaggle\\venv\\lib\\site-packages\\PIL\\Image.py:718\u001B[0m, in \u001B[0;36mImage.tobytes\u001B[1;34m(self, encoder_name, *args)\u001B[0m\n\u001B[0;32m    715\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m encoder_name \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mraw\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m args \u001B[38;5;241m==\u001B[39m ():\n\u001B[0;32m    716\u001B[0m     args \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmode\n\u001B[1;32m--> 718\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    720\u001B[0m \u001B[38;5;66;03m# unpack data\u001B[39;00m\n\u001B[0;32m    721\u001B[0m e \u001B[38;5;241m=\u001B[39m _getencoder(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmode, encoder_name, args)\n",
      "File \u001B[1;32mc:\\documente\\facultate_an_2\\sem2\\ia\\kaggle\\venv\\lib\\site-packages\\PIL\\ImageFile.py:267\u001B[0m, in \u001B[0;36mImageFile.load\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    264\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mload_end()\n\u001B[0;32m    266\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_exclusive_fp \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_close_exclusive_fp_after_loading:\n\u001B[1;32m--> 267\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mclose\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    268\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfp \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    270\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmap \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m LOAD_TRUNCATED_IMAGES \u001B[38;5;129;01mand\u001B[39;00m err_code \u001B[38;5;241m<\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m    271\u001B[0m     \u001B[38;5;66;03m# still raised if decoder fails to return anything\u001B[39;00m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "k = 17\n",
    "\n",
    "for lr in [0.01, 0.1] :\n",
    "    epoch = 400\n",
    "    run_model(lr, epoch, \"test_nr\" + str(k), k)\n",
    "    k += 1\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "f = open(\"cnn_62_acc_best_acc.txt\", 'w')\n",
    "f.write(\"id,label\\n\")\n",
    "i = 0\n",
    "\n",
    "d = {}\n",
    "\n",
    "model = CnnModel()\n",
    "model.to(device)\n",
    "model.load_state_dict(torch.load(\"./models/modelgreater_62.pth\"))\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in dataloader_test:\n",
    "        imgs, labels = data\n",
    "        imgs = imgs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        output = model(imgs)\n",
    "        _, predicteed = torch.max(output.data, 1)\n",
    "\n",
    "        for label in predicteed :\n",
    "            f.write(f\"{test_data.id[i]},{label}\\n\")\n",
    "            i += 1\n",
    "\n",
    "f.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "f = open(\"cnn_6th_try.txt\", 'w')\n",
    "f.write(\"id,label\\n\")\n",
    "i = 0\n",
    "net = CnnModel()\n",
    "net.load_state_dict(torch.load(\"./model1.pth\"))\n",
    "with torch.no_grad():\n",
    "    for data in dataloader:\n",
    "        imgs, labels = data\n",
    "        output = net(imgs)\n",
    "        _, predicteed = torch.max(output.data, 1)\n",
    "\n",
    "        for label in predicteed :\n",
    "            f.write(f\"{test_data.id[i]},{label}\\n\")\n",
    "            i+=1\n",
    "\n",
    "f.close()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "lr = 0.01\n",
    "epochs = 100\n",
    "\n",
    "model = CnnModel()\n",
    "model.to(device)\n",
    "\n",
    "optimizer = SGD(model.parameters(), lr = lr)\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch in range(epochs) :\n",
    "\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for i,data in enumerate(train_dataloader, 0):\n",
    "\n",
    "        images,labels = data\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(images)\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        if i % 100 == 99:    # print every 2000 mini-batches\n",
    "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 100:.3f}')\n",
    "            running_loss = 0.0\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "f = open(\"cnn_third_try.txt\", 'w')\n",
    "f.write(\"id,label\\n\")\n",
    "i = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in dataloader:\n",
    "        imgs, labels = data\n",
    "        output = model(imgs)\n",
    "        _, predicteed = torch.max(output.data, 1)\n",
    "\n",
    "        for label in predicteed :\n",
    "            f.write(f\"{test_data.id[i]},{label}\\n\")\n",
    "            i += 1\n",
    "\n",
    "f.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}